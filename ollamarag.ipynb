{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-16T11:37:25.595647Z",
     "start_time": "2025-04-16T11:37:25.592074Z"
    }
   },
   "source": [
    "import chromadb\n",
    "import os\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm_model_name = \"gemma3\""
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:49:20.410705Z",
     "start_time": "2025-04-17T14:49:20.064435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from embeds import embedding_func\n",
    "\n",
    "# Configure ChromaDB\n",
    "# Initialize the ChromaDB client with persistent storage in the current directory\n",
    "chroma_client = chromadb.PersistentClient(path=os.path.join(os.getcwd(), \"chroma_db\"))\n",
    "\n",
    "collection_name = \"rag_philosophy_cosine\"\n",
    "collection = chroma_client.get_or_create_collection(name=collection_name, embedding_function=embedding_func)"
   ],
   "id": "8b559442dc599921",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T13:11:45.092240Z",
     "start_time": "2025-04-17T13:11:45.087854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to query the ChromaDB collection\n",
    "def query_chromadb(query_text, n_results=1):\n",
    "    \"\"\"\n",
    "    Query the ChromaDB collection for relevant documents.\n",
    "\n",
    "    Args:\n",
    "        query_text (str): The input query.\n",
    "        n_results (int): The number of top results to return.\n",
    "\n",
    "    Returns:\n",
    "        list of dict: The top matching documents and their metadata.\n",
    "    \"\"\"\n",
    "    results = collection.query(\n",
    "        query_texts=[query_text],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    return results[\"documents\"], results[\"metadatas\"]\n",
    "\n",
    "\n",
    "# Function to interact with the Ollama LLM\n",
    "def query_ollama(prompt):\n",
    "    \"\"\"\n",
    "    Send a query to Ollama and retrieve the response.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The input prompt for Ollama.\n",
    "\n",
    "    Returns:\n",
    "        str: The response from Ollama.\n",
    "    \"\"\"\n",
    "    llm = OllamaLLM(model=llm_model_name)\n",
    "    return llm.invoke(prompt)\n",
    "\n",
    "\n",
    "# RAG pipeline: Combine ChromaDB and Ollama for Retrieval-Augmented Generation\n",
    "def rag_pipeline(query_text):\n",
    "    \"\"\"\n",
    "    Perform Retrieval-Augmented Generation (RAG) by combining ChromaDB and Ollama.\n",
    "\n",
    "    Args:\n",
    "        query_text (str): The input query.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response from Ollama augmented with retrieved context.\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve relevant documents from ChromaDB\n",
    "    retrieved_docs, metadata = query_chromadb(query_text)\n",
    "    context = \" \".join(retrieved_docs[0]) if retrieved_docs else \"No relevant documents found.\"\n",
    "\n",
    "    # Step 2: Send the query along with the context to Ollama\n",
    "    augmented_prompt = f\"Context: {context}\\n\\nQuestion: {query_text}\\nAnswer:\"\n",
    "    print(\"######## Augmented Prompt ########\")\n",
    "    print(augmented_prompt)\n",
    "\n",
    "    response = query_ollama(augmented_prompt)\n",
    "    return response"
   ],
   "id": "9e6fa685ed357ff8",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:49:27.319945Z",
     "start_time": "2025-04-17T14:49:24.336027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"aurelius?\"  # Change the query as needed\n",
    "results = collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=3\n",
    ")"
   ],
   "id": "516e77e8db16a6dd",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:49:33.246683Z",
     "start_time": "2025-04-17T14:49:29.130212Z"
    }
   },
   "cell_type": "code",
   "source": "rag_pipeline(\"aurelius\")",
   "id": "2ba296cacac54bb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Augmented Prompt ########\n",
      "Context: format was the Codex, which is basically like a modern book with pages made from folded paper or parchment bound between covers. The Codex begins to appear in about the 3rd century AD, especially with legal texts having evolved from the practice of tying together leaves of parchment to make a sort of notebook. Codices begin to outnumber scrolls at about 400 AD, but do not displace them completely until the 7th century or so. A couple of centuries later, the scribes introduce a second innovation. They begin writing in so-called minuscule texts, which you can roughly think of as lowercase letters instead of the old maguscule uppercase letters. But the use of maguscule for more formal texts persists for a good while. Our oldest surviving minuscule text is from the year 835, but still in the 11th century, maguscule is still found in liturgical manuscripts. And finally we have the introduction of paper about a century after scribes started writing everything in the new minuscule script. All of this might lead us to expect that a pagan work like a treatise by Aristotle would have initially existed on papyrus scrolls written in maguscule, one or more of which would be copied in the same script onto a papyrus codex, then into a parchment codex, then into a minuscule text but also in parchment, before finally being copied in the sort of format that usually survives today, a paper codex with minuscule script. While this is the right sequence in technological terms, a given work might not have existed in every form I've just listed. In particular, during the so-called Dark Ages of Byzantium, few pagan works were copied. Once interest in them reawakened, the scribes would have had to use texts in long outmoded formats as their basis. Thus a 9th century paper minuscule copy might be based directly on maguscule parchment from the 6th century. So it's a good thing that parchment is such a durable material. Books were copied and kept in a number of different contexts. The first thing that leaps to mind would be major institutions like the famous Library at Alexandria. It was important not only because of the sheer quantity of literature it held, but also because scholars working there produced the editions that usually lie behind later Byzantine copies. Generally speaking, when modern day philologists try to establish the text of a classical author, like Homer or Plato, they are really trying to get as close as possible to the Alexandrian edition of late antiquity, since it isn't possible to go back further than that. By Xantium, monasteries were less important centers of text production than in the Latin West with a more significant role played by royal and patriarchal libraries. But we should not underestimate the role of smaller schools and private libraries. Institutions such as the ancient libraries at Alexandria and Pergamon, or the collection of books we assume existed at a philosophical institute set up by the Byzantine Caesar\n",
      "\n",
      "Question: aurelius\n",
      "Answer:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Given the text, here's how we can address the question about Marcus Aurelius:\\n\\n**Answer:** A 9th century paper minuscule copy might be based directly on maguscule parchment from the 6th century.  (This response highlights the potential for a surviving copy of Aurelius's *Meditations* – a key work of the philosopher – to have originated from an older, maguscule parchment manuscript.)\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 121
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
